# rl_agent/training/config.yaml
# the documentation of this file can be found at README.md for this agent.

env_params:
  num_cards: 4
  starting_bankroll: 5

pbt_params:
  population_size: 28
  generations: 300
  matches_per_generation: 2500
  benchmark_match_prob: 0.3
  exploit_bottom_k_percent: 20

evaluation_params:
  evaluate_every: 1
  internal_matches_per_pair: 200
  benchmark_matches: 500

hyperparameter_space:
  hidden_size: [128]
  batch_size: [128]

  rl_learning_rate: [0.0001, 0.001]
  sl_learning_rate: [0.00001, 0.0001]

  gamma: [0.95, 0.999]
  tau: [0.001, 0.01]

  gradient_clip: [1.0, 10.0]
  eta: [0.05, 0.2]

  rl_buffer_size: [100000, 200000]
  sl_buffer_size: [250000, 500000]


checkpointing:
  output_dir: "rl_agent/training/training_outs/4_card_run"
  save_every_n_generations: 1